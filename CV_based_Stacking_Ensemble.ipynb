{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': '/home/ubuntu/anaconda3/envs/Manta/lib/python3.7/site-packages/sklearn/datasets/data/breast_cancer.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training , X_testing , y_training , y_testing = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4) #K최근접이웃\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)#랜덤포레스트\n",
    "dt_clf = DecisionTreeClassifier() #결정트리\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100) #아다부스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_training, y_training)  \n",
    "rf_clf.fit(X_training , y_training)  \n",
    "dt_clf.fit(X_training , y_training)\n",
    "ada_clf.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (455,), (114, 30))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training.shape, y_training.shape, X_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_testing)\n",
    "rf_pred = rf_clf.predict(X_testing)\n",
    "dt_pred = dt_clf.predict(X_testing)\n",
    "ada_pred = ada_clf.predict(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9211\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "결정 트리 정확도: 0.9035\n",
      "에이다부스트 정확도: 0.9561 :\n"
     ]
    }
   ],
   "source": [
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_testing, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_testing, rf_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_testing, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f} :'.format(accuracy_score(y_testing, ada_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114,), (114,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred.shape, rf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n"
     ]
    }
   ],
   "source": [
    "# 시험데이터로 예측한 4가지 모델의 결과를 합침\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 분류기 모델 생성\n",
    "lr_final = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# 최종 분류기 학습 및 예측\n",
    "lr_final.fit(pred, y_testing)\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_testing , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV 기반 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 안된거 다시 가져옴\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4) #K최근접이웃\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)#랜덤포레스트\n",
    "dt_clf = DecisionTreeClassifier() #결정트리\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100) #아다부스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=7, random_state=0, shuffle=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=7, shuffle=True, random_state=0)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fold_pred = np.zeros((X_training.shape[0] ,1))\n",
    "train_fold_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.zeros((X_testing.shape[0],7))\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n"
     ]
    }
   ],
   "source": [
    "print(knn_clf.__class__.__name__ , ' model 시작 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.005e+01, 1.753e+01, 6.441e+01, ..., 6.499e-02, 2.894e-01,\n",
       "        7.664e-02],\n",
       "       [1.080e+01, 2.198e+01, 6.879e+01, ..., 7.485e-02, 2.965e-01,\n",
       "        7.662e-02],\n",
       "       [1.614e+01, 1.486e+01, 1.043e+02, ..., 1.129e-01, 2.778e-01,\n",
       "        7.012e-02],\n",
       "       ...,\n",
       "       [9.436e+00, 1.832e+01, 5.982e+01, ..., 5.052e-02, 2.454e-01,\n",
       "        8.136e-02],\n",
       "       [9.720e+00, 1.822e+01, 6.073e+01, ..., 0.000e+00, 1.909e-01,\n",
       "        6.559e-02],\n",
       "       [1.151e+01, 2.393e+01, 7.452e+01, ..., 9.653e-02, 2.112e-01,\n",
       "        8.732e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index :  [  0   2   3   4   5   7   8   9  11  13  14  16  17  18  19  20  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  55  57  58  59  61  62  63\n",
      "  64  65  66  67  68  69  70  72  73  74  75  77  79  80  81  82  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  97  98  99 100 101 102 103\n",
      " 104 105 106 108 109 110 111 112 114 115 116 117 119 120 121 123 125 126\n",
      " 127 128 129 130 131 133 134 135 136 137 138 139 140 142 143 145 146 147\n",
      " 148 149 150 151 152 154 155 156 157 158 160 161 162 163 165 166 167 168\n",
      " 169 170 172 173 174 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 192 193 195 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      " 210 211 212 214 215 216 217 218 222 223 225 226 227 228 229 230 231 232\n",
      " 233 234 235 236 237 239 240 241 242 243 244 247 248 249 250 251 252 253\n",
      " 254 256 257 258 259 260 262 263 265 266 267 269 270 272 273 274 275 276\n",
      " 277 279 280 281 282 283 285 286 287 288 290 291 292 294 295 296 297 299\n",
      " 300 301 302 303 304 305 306 307 309 310 311 312 313 314 315 316 317 318\n",
      " 319 320 321 322 323 324 325 326 327 328 330 331 332 333 334 335 337 338\n",
      " 339 341 342 343 344 345 347 348 349 350 351 352 353 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 370 371 372 373 374 375 376 377 378 379\n",
      " 381 382 384 385 386 387 388 389 390 392 393 394 395 396 397 398 399 400\n",
      " 402 403 404 405 406 407 408 409 410 411 412 413 415 416 417 418 419 420\n",
      " 421 422 423 425 426 427 428 429 430 432 433 434 435 436 437 438 439 440\n",
      " 441 442 443 445 446 447 449 450 451 452 453 454]\n",
      "valid_index :  [  1   6  10  12  15  21  37  54  56  60  71  76  78  96 107 113 118 122\n",
      " 124 132 141 144 153 159 164 171 175 191 194 196 213 219 220 221 224 238\n",
      " 245 246 255 261 264 268 271 278 284 289 293 298 308 329 336 340 346 354\n",
      " 368 369 380 383 391 401 414 424 431 444 448]\n",
      "------------------------------------------------------------------------\n",
      "train_index :  [  0   1   2   3   6   9  10  11  12  13  15  16  17  18  19  21  23  24\n",
      "  25  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43\n",
      "  44  46  47  48  50  51  53  54  56  57  58  60  61  62  63  66  67  69\n",
      "  70  71  72  73  76  77  78  79  80  82  83  84  85  86  87  88  89  91\n",
      "  92  93  94  95  96  97  98  99 101 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 136 137 138 139 140 141 143 144 145 146 147 148 149\n",
      " 150 151 152 153 156 158 159 161 162 163 164 165 166 167 168 169 171 172\n",
      " 173 174 175 176 177 178 180 181 182 183 184 185 187 189 190 191 192 193\n",
      " 194 195 196 197 199 201 202 203 204 206 207 209 211 212 213 214 215 216\n",
      " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 234 235\n",
      " 237 238 240 241 242 243 244 245 246 247 248 249 251 254 255 256 257 258\n",
      " 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276\n",
      " 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294\n",
      " 296 298 300 301 302 303 304 305 307 308 309 311 313 314 315 316 317 318\n",
      " 319 320 321 322 323 324 325 326 327 328 329 330 331 333 334 335 336 337\n",
      " 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355\n",
      " 356 358 359 360 361 362 364 365 366 367 368 369 370 371 372 373 374 375\n",
      " 376 377 378 379 380 381 383 384 385 387 388 389 390 391 395 396 397 398\n",
      " 400 401 402 403 404 405 407 408 409 410 412 413 414 415 416 417 419 421\n",
      " 422 423 424 425 426 427 429 430 431 432 433 434 435 436 437 438 439 441\n",
      " 442 443 444 445 446 447 448 449 450 451 452 453]\n",
      "valid_index :  [  4   5   7   8  14  20  22  26  45  49  52  55  59  64  65  68  74  75\n",
      "  81  90 100 102 135 142 154 155 157 160 170 179 186 188 198 200 205 208\n",
      " 210 233 236 239 250 252 253 295 297 299 306 310 312 332 357 363 382 386\n",
      " 392 393 394 399 406 411 418 420 428 440 454]\n",
      "------------------------------------------------------------------------\n",
      "train_index :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  19\n",
      "  20  21  22  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  64  65  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  90  91  94  95  96  97\n",
      "  98  99 100 102 104 105 107 108 109 110 111 113 115 117 118 119 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 135 137 138 139 141 142 143\n",
      " 144 147 148 149 151 152 153 154 155 156 157 159 160 161 162 163 164 165\n",
      " 166 167 169 170 171 172 173 174 175 177 178 179 180 181 182 183 184 185\n",
      " 186 187 188 189 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222\n",
      " 223 224 226 227 228 232 233 234 235 236 237 238 239 240 242 243 244 245\n",
      " 246 248 249 250 251 252 253 255 256 257 258 259 260 261 262 264 265 266\n",
      " 267 268 269 270 271 272 273 275 277 278 279 280 284 285 286 288 289 290\n",
      " 291 292 293 294 295 296 297 298 299 300 303 304 305 306 307 308 309 310\n",
      " 311 312 314 315 316 317 318 319 320 321 322 323 324 327 328 329 331 332\n",
      " 333 334 335 336 337 338 340 341 342 344 345 346 347 348 349 350 351 352\n",
      " 354 356 357 358 359 361 362 363 365 366 367 368 369 370 371 374 375 376\n",
      " 378 379 380 381 382 383 384 386 387 388 389 390 391 392 393 394 396 397\n",
      " 398 399 401 402 403 404 405 406 407 408 409 411 412 413 414 415 418 419\n",
      " 420 421 422 423 424 425 426 428 429 430 431 432 433 435 436 438 439 440\n",
      " 441 442 443 444 445 446 447 448 449 452 453 454]\n",
      "valid_index :  [ 17  18  30  63  66  89  92  93 101 103 106 112 114 116 120 134 136 140\n",
      " 145 146 150 158 168 176 190 225 229 230 231 241 247 254 263 274 276 281\n",
      " 282 283 287 301 302 313 325 326 330 339 343 353 355 360 364 372 373 377\n",
      " 385 395 400 410 416 417 427 434 437 450 451]\n",
      "------------------------------------------------------------------------\n",
      "train_index :  [  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  28  30  31  32  36  37  38  39  40  41\n",
      "  42  43  45  47  48  49  50  52  53  54  55  56  57  58  59  60  62  63\n",
      "  64  65  66  67  68  69  70  71  72  74  75  76  77  78  79  80  81  82\n",
      "  83  84  86  87  88  89  90  91  92  93  94  95  96  98  99 100 101 102\n",
      " 103 105 106 107 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 127 128 129 130 131 132 134 135 136 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 157 158 159 160 161 163 164\n",
      " 165 166 168 169 170 171 172 174 175 176 177 178 179 180 182 183 184 185\n",
      " 186 187 188 190 191 192 193 194 195 196 197 198 200 201 202 203 205 207\n",
      " 208 209 210 211 213 216 219 220 221 222 223 224 225 226 227 228 229 230\n",
      " 231 233 234 236 237 238 239 241 242 243 244 245 246 247 248 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289\n",
      " 290 291 292 293 294 295 296 297 298 299 301 302 304 305 306 307 308 309\n",
      " 310 312 313 314 318 319 321 322 323 324 325 326 327 328 329 330 332 333\n",
      " 334 335 336 337 338 339 340 341 343 344 345 346 350 352 353 354 355 356\n",
      " 357 358 359 360 361 362 363 364 365 368 369 370 372 373 374 376 377 378\n",
      " 379 380 381 382 383 385 386 388 389 390 391 392 393 394 395 396 397 398\n",
      " 399 400 401 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417\n",
      " 418 419 420 421 422 423 424 426 427 428 429 431 433 434 436 437 438 439\n",
      " 440 441 442 444 447 448 449 450 451 452 453 454]\n",
      "valid_index :  [  2  27  29  33  34  35  44  46  51  61  73  85  97 104 108 126 133 137\n",
      " 138 156 162 167 173 181 189 199 204 206 212 214 215 217 218 232 235 240\n",
      " 249 272 300 303 311 315 316 317 320 331 342 347 348 349 351 366 367 371\n",
      " 375 384 387 402 425 430 432 435 443 445 446]\n",
      "------------------------------------------------------------------------\n",
      "train_index :  [  0   1   2   4   5   6   7   8   9  10  12  14  15  17  18  20  21  22\n",
      "  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  41  42  43\n",
      "  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61\n",
      "  62  63  64  65  66  68  69  70  71  72  73  74  75  76  78  81  82  84\n",
      "  85  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103\n",
      " 104 105 106 107 108 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 126 127 128 130 131 132 133 134 135 136 137 138 140 141 142 143 144 145\n",
      " 146 147 148 150 151 153 154 155 156 157 158 159 160 162 163 164 165 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 183 185 186 187\n",
      " 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205\n",
      " 206 207 208 209 210 211 212 213 214 215 217 218 219 220 221 222 224 225\n",
      " 227 229 230 231 232 233 235 236 238 239 240 241 242 243 244 245 246 247\n",
      " 249 250 251 252 253 254 255 256 257 261 262 263 264 265 267 268 270 271\n",
      " 272 273 274 276 277 278 279 281 282 283 284 285 287 288 289 290 291 292\n",
      " 293 295 297 298 299 300 301 302 303 304 305 306 308 310 311 312 313 314\n",
      " 315 316 317 320 321 323 324 325 326 329 330 331 332 333 334 335 336 337\n",
      " 338 339 340 341 342 343 345 346 347 348 349 351 353 354 355 356 357 358\n",
      " 359 360 361 362 363 364 366 367 368 369 370 371 372 373 375 376 377 378\n",
      " 380 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 398 399\n",
      " 400 401 402 403 404 405 406 407 409 410 411 413 414 415 416 417 418 419\n",
      " 420 421 422 423 424 425 426 427 428 430 431 432 434 435 436 437 438 439\n",
      " 440 441 442 443 444 445 446 448 450 451 453 454]\n",
      "valid_index :  [  3  11  13  16  19  24  36  40  67  77  79  80  83  86 109 110 111 125\n",
      " 129 139 149 152 161 166 182 184 216 223 226 228 234 237 248 258 259 260\n",
      " 266 269 275 280 286 294 296 307 309 318 319 322 327 328 344 350 352 365\n",
      " 374 379 381 397 408 412 429 433 447 449 452]\n",
      "------------------------------------------------------------------------\n",
      "train_index :  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  44  45  46  47  49  51  52  53  54  55  56  59  60  61  63\n",
      "  64  65  66  67  68  70  71  72  73  74  75  76  77  78  79  80  81  83\n",
      "  85  86  87  88  89  90  92  93  96  97  99 100 101 102 103 104 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 122 124 125 126 127 128\n",
      " 129 132 133 134 135 136 137 138 139 140 141 142 144 145 146 147 149 150\n",
      " 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n",
      " 170 171 172 173 174 175 176 177 179 181 182 183 184 185 186 188 189 190\n",
      " 191 192 193 194 195 196 197 198 199 200 202 204 205 206 208 210 211 212\n",
      " 213 214 215 216 217 218 219 220 221 223 224 225 226 228 229 230 231 232\n",
      " 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250\n",
      " 251 252 253 254 255 258 259 260 261 263 264 265 266 268 269 271 272 273\n",
      " 274 275 276 277 278 280 281 282 283 284 285 286 287 288 289 290 292 293\n",
      " 294 295 296 297 298 299 300 301 302 303 306 307 308 309 310 311 312 313\n",
      " 314 315 316 317 318 319 320 322 323 325 326 327 328 329 330 331 332 333\n",
      " 335 336 337 338 339 340 342 343 344 346 347 348 349 350 351 352 353 354\n",
      " 355 357 359 360 363 364 365 366 367 368 369 370 371 372 373 374 375 377\n",
      " 379 380 381 382 383 384 385 386 387 388 389 391 392 393 394 395 396 397\n",
      " 398 399 400 401 402 404 405 406 408 410 411 412 413 414 415 416 417 418\n",
      " 420 421 423 424 425 426 427 428 429 430 431 432 433 434 435 437 439 440\n",
      " 441 443 444 445 446 447 448 449 450 451 452 454]\n",
      "valid_index :  [  0  23  41  42  43  48  50  57  58  62  69  82  84  91  94  95  98 105\n",
      " 119 121 123 130 131 143 148 169 178 180 187 201 203 207 209 222 227 256\n",
      " 257 262 267 270 279 291 304 305 321 324 334 341 345 356 358 361 362 376\n",
      " 378 390 403 407 409 419 422 436 438 442 453]\n",
      "------------------------------------------------------------------------\n",
      "train_index :  [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  26  27  29  30  33  34  35  36  37  40  41  42\n",
      "  43  44  45  46  48  49  50  51  52  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  71  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  89  90  91  92  93  94  95  96  97  98 100 101 102 103\n",
      " 104 105 106 107 108 109 110 111 112 113 114 116 118 119 120 121 122 123\n",
      " 124 125 126 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 148 149 150 152 153 154 155 156 157 158 159 160 161 162 164\n",
      " 166 167 168 169 170 171 173 175 176 178 179 180 181 182 184 186 187 188\n",
      " 189 190 191 194 196 198 199 200 201 203 204 205 206 207 208 209 210 212\n",
      " 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230\n",
      " 231 232 233 234 235 236 237 238 239 240 241 245 246 247 248 249 250 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 266 267 268 269 270 271\n",
      " 272 274 275 276 278 279 280 281 282 283 284 286 287 289 291 293 294 295\n",
      " 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313\n",
      " 315 316 317 318 319 320 321 322 324 325 326 327 328 329 330 331 332 334\n",
      " 336 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355\n",
      " 356 357 358 360 361 362 363 364 365 366 367 368 369 371 372 373 374 375\n",
      " 376 377 378 379 380 381 382 383 384 385 386 387 390 391 392 393 394 395\n",
      " 397 399 400 401 402 403 406 407 408 409 410 411 412 414 416 417 418 419\n",
      " 420 422 424 425 427 428 429 430 431 432 433 434 435 436 437 438 440 442\n",
      " 443 444 445 446 447 448 449 450 451 452 453 454]\n",
      "valid_index :  [  9  25  28  31  32  38  39  47  53  70  72  87  88  99 115 117 127 128\n",
      " 147 151 163 165 172 174 177 183 185 192 193 195 197 202 211 242 243 244\n",
      " 251 265 273 277 285 288 290 292 314 323 333 335 337 338 359 370 388 389\n",
      " 396 398 404 405 413 415 421 423 426 439 441]\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for (train_index, valid_index) in kf.split(X_training):\n",
    "    print(\"train_index : \", train_index)\n",
    "    print(\"valid_index : \", valid_index)\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(390,)\n",
      "(65,)\n",
      "1\n",
      "(390,)\n",
      "(65,)\n",
      "2\n",
      "(390,)\n",
      "(65,)\n",
      "3\n",
      "(390,)\n",
      "(65,)\n",
      "4\n",
      "(390,)\n",
      "(65,)\n",
      "5\n",
      "(390,)\n",
      "(65,)\n",
      "6\n",
      "(390,)\n",
      "(65,)\n"
     ]
    }
   ],
   "source": [
    "for index, (train, test) in enumerate(kf.split(X_training)):\n",
    "    print(index)\n",
    "    print(train.shape)\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " [1.218e+01 1.784e+01 7.779e+01 ... 5.882e-02 2.227e-01 7.376e-02]\n",
      " ...\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1\n",
      " 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1]\n",
      "[[1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.174e+01 1.402e+01 7.424e+01 ... 8.290e-02 3.101e-01 6.688e-02]\n",
      " [2.020e+01 2.683e+01 1.337e+02 ... 2.152e-01 3.271e-01 7.632e-02]\n",
      " ...\n",
      " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]\n",
      " [1.113e+01 2.244e+01 7.149e+01 ... 6.413e-02 3.169e-01 8.032e-02]\n",
      " [1.492e+01 1.493e+01 9.645e+01 ... 1.147e-01 2.688e-01 8.273e-02]]\n",
      "----------------------------------------------------------------------------\n",
      "1\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " ...\n",
      " [1.246e+01 2.404e+01 8.397e+01 ... 2.210e-01 4.366e-01 2.075e-01]\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1\n",
      " 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
      " 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 0 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1\n",
      " 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1]\n",
      "[[1.225e+01 2.244e+01 7.818e+01 ... 6.335e-02 3.100e-01 8.203e-02]\n",
      " [1.328e+01 1.372e+01 8.579e+01 ... 9.173e-02 2.736e-01 7.320e-02]\n",
      " [1.267e+01 1.730e+01 8.125e+01 ... 5.602e-02 2.688e-01 6.888e-02]\n",
      " ...\n",
      " [1.940e+01 2.350e+01 1.291e+02 ... 1.564e-01 2.920e-01 7.614e-02]\n",
      " [1.720e+01 2.452e+01 1.142e+02 ... 1.899e-01 3.313e-01 1.339e-01]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "----------------------------------------------------------------------------\n",
      "2\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " ...\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "[1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0\n",
      " 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1\n",
      " 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1\n",
      " 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0\n",
      " 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 1 0\n",
      " 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1]\n",
      "[[1.008e+01 1.511e+01 6.376e+01 ... 1.042e-02 2.933e-01 7.697e-02]\n",
      " [1.320e+01 1.582e+01 8.407e+01 ... 2.500e-02 2.651e-01 8.385e-02]\n",
      " [1.122e+01 1.986e+01 7.194e+01 ... 2.022e-02 3.292e-01 6.522e-02]\n",
      " ...\n",
      " [1.453e+01 1.934e+01 9.425e+01 ... 9.594e-02 2.471e-01 7.463e-02]\n",
      " [1.881e+01 1.998e+01 1.209e+02 ... 1.294e-01 2.567e-01 5.737e-02]\n",
      " [1.246e+01 2.404e+01 8.397e+01 ... 2.210e-01 4.366e-01 2.075e-01]]\n",
      "----------------------------------------------------------------------------\n",
      "3\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.218e+01 1.784e+01 7.779e+01 ... 5.882e-02 2.227e-01 7.376e-02]\n",
      " ...\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "[1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 1 1\n",
      " 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1\n",
      " 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1]\n",
      "[[1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " [1.353e+01 1.094e+01 8.791e+01 ... 7.407e-02 2.710e-01 7.191e-02]\n",
      " [1.185e+01 1.746e+01 7.554e+01 ... 9.140e-02 3.101e-01 7.007e-02]\n",
      " ...\n",
      " [1.902e+01 2.459e+01 1.220e+02 ... 1.956e-01 3.956e-01 9.288e-02]\n",
      " [1.464e+01 1.685e+01 9.421e+01 ... 7.828e-02 2.455e-01 6.596e-02]\n",
      " [8.597e+00 1.860e+01 5.409e+01 ... 0.000e+00 3.142e-01 8.116e-02]]\n",
      "----------------------------------------------------------------------------\n",
      "4\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " ...\n",
      " [1.246e+01 2.404e+01 8.397e+01 ... 2.210e-01 4.366e-01 2.075e-01]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "[1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1\n",
      " 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1\n",
      " 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1\n",
      " 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0\n",
      " 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 0 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 1\n",
      " 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1]\n",
      "[[1.218e+01 1.784e+01 7.779e+01 ... 5.882e-02 2.227e-01 7.376e-02]\n",
      " [1.162e+01 1.818e+01 7.638e+01 ... 1.416e-01 2.660e-01 9.270e-02]\n",
      " [1.129e+01 1.304e+01 7.223e+01 ... 8.750e-02 2.733e-01 8.022e-02]\n",
      " ...\n",
      " [1.351e+01 1.889e+01 8.810e+01 ... 1.453e-01 2.666e-01 7.686e-02]\n",
      " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]]\n",
      "----------------------------------------------------------------------------\n",
      "5\n",
      "[[1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " [1.218e+01 1.784e+01 7.779e+01 ... 5.882e-02 2.227e-01 7.376e-02]\n",
      " ...\n",
      " [1.246e+01 2.404e+01 8.397e+01 ... 2.210e-01 4.366e-01 2.075e-01]\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "[1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1\n",
      " 1 0 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1\n",
      " 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0\n",
      " 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1]\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.505e+01 1.907e+01 9.726e+01 ... 1.120e-01 2.282e-01 6.954e-02]\n",
      " [1.478e+01 2.394e+01 9.740e+01 ... 1.614e-01 3.321e-01 8.911e-02]\n",
      " ...\n",
      " [1.240e+01 1.768e+01 8.147e+01 ... 7.370e-02 2.556e-01 9.359e-02]\n",
      " [1.066e+01 1.515e+01 6.749e+01 ... 0.000e+00 2.710e-01 6.164e-02]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]]\n",
      "----------------------------------------------------------------------------\n",
      "6\n",
      "[[1.005e+01 1.753e+01 6.441e+01 ... 6.499e-02 2.894e-01 7.664e-02]\n",
      " [1.080e+01 2.198e+01 6.879e+01 ... 7.485e-02 2.965e-01 7.662e-02]\n",
      " [1.614e+01 1.486e+01 1.043e+02 ... 1.129e-01 2.778e-01 7.012e-02]\n",
      " ...\n",
      " [9.436e+00 1.832e+01 5.982e+01 ... 5.052e-02 2.454e-01 8.136e-02]\n",
      " [9.720e+00 1.822e+01 6.073e+01 ... 0.000e+00 1.909e-01 6.559e-02]\n",
      " [1.151e+01 2.393e+01 7.452e+01 ... 9.653e-02 2.112e-01 8.732e-02]]\n",
      "[1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1\n",
      " 0 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0\n",
      " 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1\n",
      " 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0\n",
      " 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1\n",
      " 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1\n",
      " 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1]\n",
      "[[1.127e+01 1.296e+01 7.316e+01 ... 1.318e-01 3.343e-01 9.215e-02]\n",
      " [1.051e+01 2.019e+01 6.864e+01 ... 6.136e-02 2.383e-01 9.026e-02]\n",
      " [1.959e+01 1.815e+01 1.307e+02 ... 2.247e-01 3.643e-01 9.223e-02]\n",
      " ...\n",
      " [1.174e+01 1.469e+01 7.631e+01 ... 1.056e-01 2.604e-01 9.879e-02]\n",
      " [1.193e+01 2.153e+01 7.653e+01 ... 7.247e-02 2.438e-01 8.541e-02]\n",
      " [1.169e+01 2.444e+01 7.637e+01 ... 1.308e-01 2.803e-01 9.970e-02]]\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index, (train_index, valid_index) in enumerate(kf.split(X_training)):\n",
    "    print(index)\n",
    "    X_tr = X_training[train_index] \n",
    "    y_tr = y_training[train_index] \n",
    "    X_te = X_training[valid_index]\n",
    "    print(X_tr)\n",
    "    print(y_tr)\n",
    "    print(X_te)\n",
    "    print(\"----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fold_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_training[train_index] \n",
    "y_tr = y_training[train_index] \n",
    "X_te = X_training[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_tr, y_tr)\n",
    "\n",
    "train_fold_pred[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 그림.\n",
    "![nn](./white_board.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_training, y_training, X_testing, n_folds ):\n",
    "    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_training.shape[0] ,1))\n",
    "    test_pred = np.zeros((X_testing.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_training)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출\n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_train = X_training[train_index] \n",
    "        y_train = y_training[train_index] \n",
    "        X_valid = X_training[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_train , y_train)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_valid).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_testing)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455,), (114,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_training.shape, y_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "RandomForestClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "DecisionTreeClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "AdaBoostClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n"
     ]
    }
   ],
   "source": [
    "# CV스태킹 알고리즘 각 모델에 적용\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_training, y_training, X_testing, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_training, y_training, X_testing, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_training, y_training, X_testing,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_training, y_training, X_testing, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 4), (114, 4))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### CV스태킹 알고리즘 결과로 메타 모델 학습/시험에 필요한 result_a result_b 만들기 \n",
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "Stack_final_X_train.shape, Stack_final_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타 모델 학습\n",
    "lr_final.fit(Stack_final_X_train, y_training)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_testing, stack_final)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Manta",
   "language": "python",
   "name": "manta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
